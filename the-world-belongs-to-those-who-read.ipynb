{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Gray;color: white;font-family:sans-serif;font-size:200%;text-align:center\">The World Belongs to Those Who Read</h1>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport os\nImage.open(\"../input/booksbooksbooks/library-1666702_1920.jpg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:150%;text-align:center\">Table Of Content</h2>\n\n* [1. Introduction](#1)\n* [2. Libraries](#2)\n* [3. Data Understanding](#3)\n    * [3.1 Missing Values](#3.1)\n    * [3.2 Duplicates](#3.2)\n    * [3.3 Distributions](#3.3)\n* [4. Data Analysis](#4) \n    * [4.1 Which Authors Write the Most Bestsellers?](#4.1)\n    * [4.2 Which Genre Dominates which Year?](#4.2)\n    * [4.3 How does the Mean Price Change over the Years?](#4.3)\n    * [4.4 What's the Mean Price in each Genre?](#4.4)\n    * [4.5 Which Books have the Most Reviews?](#4.5)\n    * [4.6 Do Genres Differ in the Number of Reviews?](#4.6)\n    * [4.7 Which Books have the Highest User Rating?](#4.7)\n    * [4.8 How does the User Rating Change over the Years?](#4.8)\n    * [4.9 Does a Higher Rating Lead to a Higher Price?](#4.9)\n    * [4.10 Which Words make a Bestseller's Title?](#4.10)\n* [5. Models](#5) \n    * [5.1 Preprocessing](#5.1)\n    * [5.2 Choice of a Classification Metric](#5.2)\n    * [5.3 Correlations](#5.3)\n    * [5.4 What's the Genre of a Book?](#5.4)\n    * [5.5 What's the Worth (Price) of a Book?](#5.5)\n    * [5.6 How Popular is a Book?](#5.6)\n* [6. Conclusion](#6) \n* [7. Evaluation](#7) \n "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:150%;text-align:center\">Introduction</h2>"},{"metadata":{},"cell_type":"markdown","source":"In the following, we examine especially the influences on a bestseller's genre, price and user rating. Afterwards we will build models to predict those features. This is based on a dataset on Amazon's Top 50 bestselling books from 2009 to 2019. The data has been categorized into fiction and non-fiction using Goodreads. Goodreads is an American social cataloging website that allows people to search their database of books, annotations, quotes, and reviews."},{"metadata":{},"cell_type":"markdown","source":"With the data analysis the following questions will be answered and visualized:\n* Which Authors Write the Most Bestsellers?\n* Which Genre Dominates which Year?\n* How does the Mean Price Change over Years?\n* What's the Mean Price in each Genre?\n* Which Books have the Most Reviews?\n* Do Genres Differ in the Number of Reviews?\n* Which Books have the Highest User Rating?\n* How does the User Rating Change over the Years?\n* Does a Higher Rating Lead to a Higher Price?\n* Which Words make a Bestseller's Title?"},{"metadata":{},"cell_type":"markdown","source":"\nWith the models the following questions will be answered:\n* What's the genre of a book? This is actually a real life use case. I recently talked to a Data Scientist working at a bookselling company. They are currently working on models to determine the genre of their books. \n* What's the worth (price) of a book? Clearly this is an important question for authors, booksellers as well as customers.\n* How popular is a book? This allows authors and booksellers to find out the preferences of readers and to improve their work."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:150%;text-align:center\">Libraries</h2>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom wordcloud import WordCloud, STOPWORDS\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression, Ridge, Lasso\nfrom xgboost import XGBClassifier, XGBRegressor\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:150%;text-align:center\">Data Understanding</h2>"},{"metadata":{},"cell_type":"markdown","source":"Since these are bestsellers, the Amazon user ratings range from 3.3 to 4.9 of 5. Though the number of reviews written on Amazon varies considerable between the different books. The prices (as at 13/10/2020) are integers between 0 and 105. The years range from 2009-2019. The genre is only differentiated between 'Fiction' and 'Non Fiction'."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"bestsellers = pd.read_csv('/kaggle/input/amazon-top-50-bestselling-books-2009-2019/bestsellers with categories.csv')\nbestsellers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"bestsellers.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"bestsellers.rename(columns={'User Rating': 'User_Rating'}, inplace=True)\nbestsellers.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3.1\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Missing Values</h3>"},{"metadata":{},"cell_type":"markdown","source":"There are twelve entries with a price of zero. Since 'To Kill a Mockingbird\" cost 7 in 2007 and also the 'Diary of a Wimpy Kid' series normally has higher prices, we assume that these are missing values except for 'The Constitution of the United States'."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"bestsellers[bestsellers['Price'] == 0].sort_values('Author')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are just a few missing values, we can make detailed adjustments. Let's search if the authors with missing values in the price have written other bestsellers. If yes, we can derive the price from their other books. If no, we will use the mean price of the genre in the year."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"bestsellers[bestsellers['Author'].isin(['Alice Schertle', \n                                        'Harper Lee', \n                                        'Jeff Kinney', \n                                        'RH Disney', \n                                        'Stephenie Meyer'])].sort_values('Author')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Because Alice Schertle and RH Disney have not written any other bestsellers in this time, we estimate the prices by the mean price of fiction in 2014 (without the other missing values).\n* For the price of Harper Lees' 'To Kill a Mockingbird' we will take the price of the book in 2019. \n* For Jeff Kinney's 'Diary of a Wimpy Kid' we will use the mean price of the previous and the following book of the series (and round up).\n* The price of 'The Short Second Life of Bree Tanner: An Eclipse Novella (Twilight Saga)' we will estimate with the mean of the other two 'Eclipse' books of Stephenie Meyer."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Mean price for fiction books in 2014\nbestsellers_2014 = bestsellers[bestsellers['Year'] == 2014] \nprice_fiction_2014 = bestsellers_2014[bestsellers_2014['Price'] >0].groupby('Genre').mean().Price.Fiction\n# 'Little Blue Truck'\nbestsellers.loc[219, 'Price'] = price_fiction_2014\n# Disney's Frozen\nbestsellers.loc[116, 'Price'] = price_fiction_2014\nbestsellers.loc[193, 'Price'] = price_fiction_2014\n\n\n# To Kill a Mockingbird\nbestsellers.loc[bestsellers.Name == 'To Kill a Mockingbird', 'Price'] = 7\n\n# Wimpy Kid\n# 'The Getaway' is part 12 of the series. The price of part 11 is 20 and of part 13 8. The mean is 14. \nbestsellers.loc[381, 'Price'] = 14\n# Change the price of book 8. Book 9 is 'The Long Haul' with a price of 22. Book 7 has a price of 7.\nbestsellers.loc[71, 'Price'] = 15\n# Change the price of book 6.\nbestsellers.loc[42, 'Price'] = 10\n\n#The Short Second Life of Bree Tanner\nbestsellers.loc[461, 'Price'] = 13","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#Check\nbestsellers[bestsellers['Price'] == 0].sort_values('Author')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3.2\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Duplicates</h3>"},{"metadata":{},"cell_type":"markdown","source":"Many books have been bestsellers for more than one year. In this case all columns have the same value for such 'duplicate' books except for the year. Especially the number of reviews and the user rating represent the total number over all years. \n\nIn the following, we will work with a dataframe of unique bestsellers unless otherwise stated. In case of duplicates the book is assigned to the first year it has been a bestseller."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"bestsellers[bestsellers.duplicated(subset=['Name', 'Author'], keep=False)].sort_values('Name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Build a second dataframe with unique bestsellers.\n# In case of duplicates the book is assigned to the first year it has been a bestseller.\n\nunique_bestsellers = bestsellers.drop_duplicates(subset=['Name', 'Author'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3.3\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Distributions</h3>"},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at the distributions of the features:\n* The user ratings range preeminently between 4.6 and 4.8 out of 5. \n* Most books have under 10,000 ratings. \n* The prices range mainly between 0 and 20.\n* Considering the genre slightly more bestellers are non-fiction (54%) than fiction."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Take a look at the distributions\ndef distribution_plot(col, boundaries=(0, 100)):\n    \"\"\"\n    Description: Plots a histogram in order to see the distribution of the feature. \n    \n    Arguments:\n        col: column of a dataframe\n        boundaries: range that should be plotted\n        df: dataframe\n    \n    Returns:\n       A distribution plot\n    \"\"\"\n    \n    plt.figure(figsize=(4,2))\n    unique_bestsellers[col].hist(range=boundaries, bins=20, color='lightsalmon', edgecolor='palevioletred', \n                       linewidth=1)  \n    plt.grid(False)\n    plt.xlabel(col)\n    plt.ylabel('Count')\n    plt.title('Distribution of the ' + col)\n    plt.show()\n    \n\ndistribution_plot('User_Rating', boundaries=(3.3, 5))\ndistribution_plot('Reviews', boundaries=(37, 87841))\ndistribution_plot('Price', boundaries=(0, 105)) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"genre_distribution = unique_bestsellers['Genre'].value_counts()\ngenre_distribution\nplt.pie(genre_distribution, labels=['Non Fiction', 'Fiction'], autopct='%1.2f', startangle=90, \n           colors=['lightsalmon', 'palevioletred'])\n_ = plt.title('Distribution of the Genre')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h2 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:150%;text-align:center\">Data Analysis</h2>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.1\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Which Authors Write the Most Bestsellers?</h3>"},{"metadata":{},"cell_type":"markdown","source":"There are some authors who wrote several bestellers. Often it's a book series. Therefore the author will be a very important feature for the later models."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Which Authors Write the Most Bestsellers?\n\nbooks_per_author = unique_bestsellers.groupby(['Author']).count().Name.sort_values(ascending=False)\n\nplt.figure(figsize=(8,5))\nbooks_per_author.iloc[:12].plot(kind='barh', color=['purple', 'palevioletred', 'salmon', 'lightsalmon'])\nplt.title('12 Authors with the Most Bestsellers')\nplt.gca().invert_yaxis()\nplt.xlabel('Number of Bestsellers')\n_ = plt.ylabel('Author')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With twelve bestsellers (in eleven years!) Jeff Kinney is the unchallenged top author with the series 'Diary of a Wimpy Kid'."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"unique_bestsellers[unique_bestsellers['Author'] == 'Jeff Kinney']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Image.open(\"../input/booksbooksbooks/WimpyKids.jpg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.2\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Which Genre Dominates Which Year?</h3>"},{"metadata":{},"cell_type":"markdown","source":"In this case 'duplicates' are kept in the data because they represent the reader's taste of each year. Eventhough non-fiction is represented more often throughout the years, fiction dominated in 2014. Followed by a strong non fiction year in 2015."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fiction = bestsellers[bestsellers['Genre'] == 'Fiction'].groupby(['Year']).count().Genre / 50\nnon_fiction = bestsellers[bestsellers['Genre'] == 'Non Fiction'].groupby(['Year']).count().Genre / 50\n\nplt.figure(figsize=(8,5))\nfiction.plot(kind='bar', color='palevioletred')\nnon_fiction.plot(kind='bar', bottom=fiction, color='lightsalmon')\nplt.title('Which Genre Dominates Which Year?')\nplt.xlabel('Year')\nplt.ylabel('Proportion of the Total Number of Bestsellers')\nplt.legend(('Fiction', 'Non Fiction'), loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n_ = plt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.3\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">How does the Mean Price Change over Years?</h3>"},{"metadata":{},"cell_type":"raw","source":"In a contemplation of several years we have to keep the 'duplicates' in the data to avoid distortions for example because of a disproportion in the distribution of the genre. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"price_per_year = bestsellers.groupby(['Year']).mean().Price\n\nplt.figure(figsize=(8,5))\nprice_per_year.plot(kind='line', color='palevioletred')\nplt.title('Development of the Mean Price')\nplt.xlabel('Year')\n_ = plt.ylabel('Mean Price')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a downward trend in the mean price per year. Bestsellers are getting cheaper. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.4\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">What's the Mean Price in each Genre?</h3>"},{"metadata":{},"cell_type":"markdown","source":"Non fiction books are about 13% more expensive than fiction books. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Then calculate the mean price per genre\n\nprice_per_genre = unique_bestsellers.groupby(['Genre']).mean().Price\n\nplt.figure(figsize=(8,5))\nabc = price_per_genre.plot(kind='bar', color=['palevioletred', 'lightsalmon'])\nplt.title('Development of the Mean Price')\nplt.xlabel('Genre')\nplt.ylabel('Mean Price')\n_ = plt.xticks(rotation=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.5\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Which Books have the Most Reviews?</h3>"},{"metadata":{},"cell_type":"markdown","source":"The number of reviews ranges widely between 37 and 87,841. It could be an indicator for the number of books sold or how much it affects people emotionally."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# just a beauty correction for the plot\nunique_bestsellers['Name'].replace(\n    {'Fifty Shades of Grey: Book One of the Fifty Shades Trilogy (Fifty Shades of Grey Series)': \n     'Book One of the Fifty Shades Trilogy'}, \n    inplace=True)\n\n# Search for the books with the highest number of reviews\nbest_reviews = unique_bestsellers[['Name','Reviews']].groupby('Name').sum().sort_values('Reviews', ascending=False)\n\nbest_reviews.iloc[:10].plot(kind='barh', color=['salmon', 'lightsalmon'])\nplt.gcf().set_size_inches(8, 5)\nplt.title('10 Books with the Most Reviews')\nplt.gca().invert_yaxis()\nplt.xlabel('Number of Reviews')\n_ = plt.ylabel('Book')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By far the most reviews have been given to 'Where the Crawdads Sing' by Delia Owens with a user rating of 4.8 and 'The Girl on the Train' by Paula Hawkings with a user rating of 4.1. In 2016 a movie of 'The Girl on the Train' came out. However, it couldn't convince the audience as much as the book."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Image.open(\"../input/booksbooksbooks/crawdads.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Image.open(\"../input/booksbooksbooks/girlonthetrain.jpg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.6\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Do Genres Differ in the Number of Reviews?</h3>"},{"metadata":{},"cell_type":"markdown","source":"Fiction received with 2,097,771 reviews about 56% more reviews than non-fiction with 1,341,918 reviews."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"reviews_per_genre = unique_bestsellers.groupby(['Genre']).sum().Reviews\n\nplt.figure(figsize=(8,5))\nabc = reviews_per_genre.plot(kind='bar', color=['palevioletred', 'lightsalmon'])\nplt.title('Number of Reviews in each Genre')\nplt.xlabel('Genre')\nplt.ylabel('Number of Reviews')\n_ = plt.xticks(rotation=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.7\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Which Books have the Highest User Rating?</h3>"},{"metadata":{},"cell_type":"markdown","source":"28 books have the highest occurring rating of 4.9."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Books with the highest occurring rating\nunique_bestsellers[unique_bestsellers['User_Rating'] == 4.9].sort_values('Reviews', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dav Pilkey tops the list with six books that received the best user rating, followed by J.K. Rowling with 4 books."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.8\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">How does the User Rating Change over the Years?</h3>"},{"metadata":{},"cell_type":"markdown","source":"Again: In a contemplation of several years we have to keep the 'duplicates' in the data to avoid distortions for example because of a disproportion in the distribution of the genre."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"rating_per_year = bestsellers.groupby(['Year']).mean().User_Rating\n\nplt.figure(figsize=(8,5))\nrating_per_year.plot(kind='line', color='palevioletred')\nplt.title('Development of the Mean Rating')\nplt.xlabel('Year')\n_ = plt.ylabel('Mean Rating')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since 2012 we see an upward trend in the mean user rating from 4.5 to 4.7 out of 5."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.9\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Does a Higher Rating Lead to a Higher Price?</h3>"},{"metadata":{},"cell_type":"markdown","source":"There is no clear relationship between the user rating and the price. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Does a Higher Rating Lead to a Higher Price?\n\nratings_reviews = unique_bestsellers.groupby(['User_Rating']).mean().Price\n\nplt.figure(figsize=(8,5))\nratings_reviews.plot(kind='line', color='palevioletred')\nplt.title('Does a Higher Rating Lead to a Higher Price?')\nplt.xlabel('Rating')\n_ = plt.ylabel('Mean Price')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.10\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Which Words make a Bestseller Title?</h3>"},{"metadata":{},"cell_type":"markdown","source":"Since some authors have been very succesful with their whole book series, some very specific words like 'Harry Potter', 'Wimpy Kid', 'Dog Man' or ' Fifty Shade(s)' show up."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def tokenize(text):\n    \"\"\"\n    Description: This function processes texts in order to create a wordcloud. \n    \n    Arguments:\n        text: String\n    \n    Returns:\n        clean_tokens: lists of normalized, tokenized and lemmatized words of the text without stopwords\n    \"\"\"\n    \n    # normalize case and remove punctuation\n    text = re.sub(r'[^a-zA-z0-9]', ' ', text.lower())\n    \n    #tokenize text\n    tokens = word_tokenize(text) \n    \n    #lemmatize and remove stopwords\n    lemmatizer = WordNetLemmatizer()\n    clean_tokens = []\n    for tok in tokens:\n        if tok not in stopwords.words('english'):\n            \n            clean_tok = lemmatizer.lemmatize(lemmatizer.lemmatize(tok, pos='v'))\n\n            clean_tokens.append(clean_tok)\n    \n    return clean_tokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def word_list(lists):\n    \"\"\"\n    Description: This function reformats separate lists of words into one list of words.\n    \n    Arguments:\n        lists: separate lists of words\n    \n    Returns:\n        list_of_words: list of words of all lists\n    \"\"\"\n    \n    list_of_words = []\n    \n    for list in lists:\n        for word in list:\n            list_of_words.append(word)\n    return list_of_words\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot a wordcloud of tokenized book titles\nstopwords_cloud = set(STOPWORDS)\nstopwords_cloud.update(['book', 'novel'])\n\ntext = ' '.join([word for word in word_list(unique_bestsellers['Name'].apply(tokenize))])\nreading_woman = np.array(Image.open(\"../input/booksbooksbooks/book-1296329_1280_2.png\"))\ncloud = WordCloud(stopwords=stopwords_cloud, \n                  background_color='white', \n                  max_words=75, \n                  mask=reading_woman, \n                  contour_width=3, \n                  contour_color='lightsalmon').generate(text)\nplt.figure(figsize=(20, 10))\nplt.axis(\"off\")\n_ = plt.imshow(cloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n<h2 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:150%;text-align:center\">Models</h2>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.1\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Preprocessing</h3>"},{"metadata":{},"cell_type":"markdown","source":"We have already handled missing values and duplicates in the \"Data Understanding\" section which is also important to achieve good results with the model. \n\nIn case of the genre and user rating predictions books with a price of zero would have distorted the relationship between the price and the genre/user rating and could have lead to false classifications/ratings. In case of the pricing model those books could have lead to lower price predictions. \n\nIn all cases ducplicates would have lead to seemingly better models, since a part of the test data would correspond to information already known from the training data.\n\nHence, we have already excluded possible sources of error with these adjustments."},{"metadata":{},"cell_type":"markdown","source":"The models can only handle numerical data. Therefore we have to adjust the categorial data in 'Genre' as well as the strings in the book titles. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Process categorial data for modeling\nunique_bestsellers_preprocessed = pd.get_dummies(unique_bestsellers.drop(['Name'], axis=1),\n                                                 drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Process book titles with NLP methods for modeling\ntfidf = TfidfVectorizer()\ntransformed_names = tfidf.fit_transform(unique_bestsellers['Name'])\ntransformed_names_df = pd.DataFrame(transformed_names.toarray(), columns=tfidf.get_feature_names())\nunique_bestsellers_preprocessed = pd.concat([unique_bestsellers_preprocessed.reset_index(drop=True),\n                                             transformed_names_df.reset_index(drop=True)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.2\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Choice of a Classification Metric</h3>"},{"metadata":{},"cell_type":"markdown","source":"Accuracy is the basic classification metric taking the proportion of true results among the total number of cases examined. It is easy to understand but not always usefull. Fore example if we want to find spam mails: Just say 'no' all the time and you will be 98% accurate (depends on the account). If a target class is very sparse (for example spam mails), models can have a high accuracy, but not be valuable. \n\nIn our case the genre is relatively balanced, so that accuracy would be an option. Though, we will print a classification report showing the precision, recall and f1-score for each classifier.\n\nPrecision calculates the proportion of true positives among the predicted positives. It is a valid choice of evaluation metric when we want to be very sure of our prediction. The disadvantage of beeing that careful is that we would increase the number of false negatives. Therefore precision is unsuitable for our application, as no genre is more valuable.\n\nRecall determines which proportion of actual Positives is correctly classified. It is a valid choice of evaluation metric when we want to capture as many positives as possible. The problem: Recall is 1 if we predict 1 for all examples.\n\nThere is a metric utilizing tradeoff of precision vs. recall called F1 Score. The F1-score is a number between 0 and 1 and is the harmonic mean of precision and recall. F1-score sort of maintains a balance between the precision and recall for your classifier. If your precision is low, the F1 is low and if the recall is low again your F1-score is low. Since we want to have a model with both good precision and recall, we will use the F1-score."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.3\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">Correlations</h3>"},{"metadata":{},"cell_type":"markdown","source":"Let's also take a look at the heatmap to get a better feeling for correlations of the features before modeling."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Plot heatmap of correlations\nheatmap_data = unique_bestsellers_preprocessed[['User_Rating', 'Reviews', 'Price', 'Year', \n                                                'Genre_Non Fiction']]\nplt.figure(figsize=(10,10))\nsns.heatmap(heatmap_data.corr(), square=True, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The strongest negative correlation consists between year and genre with -0.28. The strongest positive correlations are between year and user rating as well as between year and reviews with 0.22."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.4\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">What's the Genre of a Book?</h3>"},{"metadata":{},"cell_type":"markdown","source":"Because it is pointless to predict the genre for books that you already know, the model is calculated on a data set that takes books that occur over a number of years only once into account. We use GridSearchCV to decide between logistic regression and XGBoost. We choose logistic regression because it's a fast and simple classification method and XGBoost because it achieves excellent results for many classification problems."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Build the train and test data sets\nX = unique_bestsellers_preprocessed.drop('Genre_Non Fiction', axis=1)\ny = unique_bestsellers_preprocessed['Genre_Non Fiction']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def scale_gridsearch(estimators, parameters, classifier):\n    \"\"\"\n    Description: This function runs a pipeline of a scaler and GridSearchCV with different estimators \n                 and prints the results.\n    \n    Arguments:\n        estimators: list of estimators to be finetuned and tested with GridsearchCV\n        parameters: list of parameters for the finetuning of the estimators\n        classifier: boolean which indicates, if it's a 1=classification or 0=regression problem\n\n    Returns:\n        None\n    \"\"\"\n    \n    for estimator, param in zip(estimators, parameters):\n        pipeline = Pipeline([\n            ('scaler', MinMaxScaler()),\n            ('cv', GridSearchCV(estimator, param_grid=param, cv=10))\n        ])\n    \n        pipeline.fit(X_train, y_train)\n        y_pred = pipeline.predict(X_test)\n        \n        print(pipeline['cv'].best_estimator_)\n        print(pipeline['cv'].best_params_)\n        \n        if classifier:\n            print(classification_report(y_test, y_pred))\n        else: \n            rmse = np.sqrt(mean_squared_error(y_test,y_pred)) \n            print('Testdata Root Mean Squared Error: {}'.format(rmse))\n            \n            \nclassifiers = [LogisticRegression(), XGBClassifier()]\n\nclf_parameters = [{'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n                   'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n                   'class_weight': ['dict', 'balanced', None]},\n                  \n                  {'booster': ['gbtree', 'gblinear', 'dart']}\n                 ]\n\n\nscale_gridsearch(estimators=classifiers, parameters=clf_parameters, classifier=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result slightly changes with each run. Sometimes one classifier dominates, sometimes the other, sometimes they achieve the same results. All in all XGBoost with a gblinear booster and logistic regression with classweight 'dict' and a newton-cg/lbfgs solver without penalty are about equally good according to their F1-score. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.5\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">What's the Worth (Price) of a Book?</h3>"},{"metadata":{},"cell_type":"raw","source":"For price prediction we use GridSearchCV to decide between ridge regression, lasso regression, random forest and XGBoost.\nWe choose\n* ridge regression and lasso regression because they are easy and fast.\n* random forest (even if it takes some time) since it is less impacted by noise beacuse of bagging.\n* XGBoost because it achieves excellent results for many regression problems.\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Build the train and test data sets\nX = unique_bestsellers_preprocessed.drop('Price', axis=1)\ny = unique_bestsellers_preprocessed['Price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"regressors = [Ridge(), Lasso(), RandomForestRegressor(), XGBRegressor()]\n\nreg_params = [{'alpha': [0.1, 0.5, 1, 5, 7, 10],\n               'tol': [0.05, 0.1, 0.5]},\n             \n              {'alpha': [0.05, 0.1, 0.5, 1, 5, 10, 20],\n               'max_iter': [100, 200, 300, 400, 500, 750]},\n             \n              {'max_depth': [20, 25, 30, 35], \n               'min_samples_split': [2, 3, 4]},\n         \n              {'booster': ['gbtree', 'gblinear', 'dart']}]\n\nscale_gridsearch(estimators=regressors, parameters=reg_params, classifier=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lasso regression shows the smallest root mean squared error of 12,96 with an alpha of 0.1 and a maximum number of iterations of 100."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.6\"></a>\n<h3 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:120%;text-align:center\">How Popular is a Book?</h3>"},{"metadata":{},"cell_type":"markdown","source":"To predict the user rating we try the same estimators as for the price prediction (ridge regression, lasso regression, random forest and XGBoost)."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Build the train and test data sets\nX = unique_bestsellers_preprocessed.drop('User_Rating', axis=1)\ny = unique_bestsellers_preprocessed['User_Rating']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"scale_gridsearch(estimators=regressors, parameters=reg_params, classifier=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this case ridge regression is the right choice with an alpha of 5 and a tol of 0.05 because of it's small root mean squared error of 0.18."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n<h2 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:150%;text-align:center\">Conclusion</h2>"},{"metadata":{},"cell_type":"markdown","source":"We took the following steps:\n* Data exploration: The features do not use the full range since the data is about bestsellers. For example there are no user ratings under 3.3 and the mean number of reviews is high.\n* Data cleaning: There were just twelve missing values that could be handled manually and some kind of duplicates when bestsellers have been successful in several years. In order to create unique data we had to decide which year we assign the book to and chose the first year of being a bestseller. For some parts of the data anlysis we had to look at the whole data set and for some at the unique data. The models have been calculated on unique data only.\n* Data analysis: We asked some questions to get to know the data and visualized the answers. The visualization of the reading girl in 'Which Words make a Bestseller Title?' has not become perfect because the contour line is not continuous.\n* Further preprocessing: The non-numerical data had to be handled in order to use them in the model\n* Classification metric: We chose the F1-score.\n* Models: Finally we built three different models using GridsearchCV for choosing the best estimator and its parameters. In cas of the genree XGBoost with a gblinear booster and logistic regression with classweight 'dict' and a newton-cg/lbfgs solver without penalty have been about equally good. In case of the price Lasso regression has been the best solution with an alpha of 0.1 and a maximum number of iterations of 100. And for the user rating ridge regression would be the right choice with an alpha of 5 and a tol of 0.05. Interesting about the project is that GridSearchCV is put into a pipeline to compare different estimators while it finetunes the parameters at the same time. We've seen that XGBoost is not always the right choice. We still have to find out the best model for each specific case. \n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a>\n<h2 style=\"background-color:Gray;color:white;font-family:sans-serif;font-size:150%;text-align:center\">Evaluation</h2>"},{"metadata":{},"cell_type":"markdown","source":"These models can only be used to a very limited extent. Since they were calculated on the basis of data about bestsellers, they can only be used for predictions concerning bestsellers. For example there would never be a prediction of the user rating under 3 or adequate prices for collectibles.\n\nFurthermore it can be unsatisfactory to predict the genre only for fiction and non-fiction. In reality, the genre would have to be divided in much more detail. The accuracy of about 87% may be too low for corporate goals. In this case, more data would have to be used, at best with additional features, to improve the model.\n\nHow could we improve our results?\n* We could extend our data to more years, more features or divide the genre in more detail.\n* There could be done more data cleaning. I.e. sometimes the same book title or author are written differently. \n* We could finetune more parameters in GridSearchCV."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}